{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression,Ridge,Lasso,ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,mean_squared_error,r2_score,make_scorer\n",
    "from sklearn.model_selection import cross_val_score,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    int64  \n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n",
      "None\n",
      "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
      "\n",
      "            LSTAT        MEDV  \n",
      "count  506.000000  506.000000  \n",
      "mean    12.653063   22.532806  \n",
      "std      7.141062    9.197104  \n",
      "min      1.730000    5.000000  \n",
      "25%      6.950000   17.025000  \n",
      "50%     11.360000   21.200000  \n",
      "75%     16.955000   25.000000  \n",
      "max     37.970000   50.000000  \n"
     ]
    }
   ],
   "source": [
    "# Load the house price data\n",
    "data = pd.read_csv('C:\\\\Users\\\\91934\\\\OneDrive\\\\Desktop\\\\GMU\\\\Ait 664\\\\Hands on session\\\\Boston-house-price-data.csv')\n",
    "print(data.info())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing=data.isnull().sum()\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "target= 'MEDV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all are in numerical columns so proceed\n",
    "X = data.drop(target,axis=1)\n",
    "y= data['MEDV']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Mean Squared Error: 21.51744423117727\n",
      "Linear Regression R^2 Score: 0.7112260057484925\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Linear Regression model\n",
    "print(\"Linear Regression Mean Squared Error:\", mean_squared_error(y_test, y_pred_linear))\n",
    "print(\"Linear Regression R^2 Score:\", r2_score(y_test, y_pred_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Mean Squared Error: 9.609646282894735\n",
      "Random Forest Regressor R^2 Score: 0.8710341288379007\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest Regressor\n",
    "print(\"Random Forest Regressor Mean Squared Error:\", mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"Random Forest Regressor R^2 Score:\", r2_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Mean Squared Error: 15.211648087327058\n",
      "Random Forest Regressor R^2 Score: 0.8710341288379007\n"
     ]
    }
   ],
   "source": [
    "# Create a RandomForestRegressor with regularization parameters\n",
    "regressor = RandomForestRegressor(\n",
    "    n_estimators=100,          # Number of trees\n",
    "    max_depth=15,              # Limit the depth of each tree\n",
    "    min_samples_split=8,       # Minimum samples required to split an internal node\n",
    "    min_samples_leaf=8,        # Minimum samples required to be at a leaf node\n",
    "    max_features='sqrt',       # Use the square root of the total features at each split\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Random Forest Regressor Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Random Forest Regressor R^2 Score:\", r2_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE from cross-validation: 16.56\n",
      "R^2 Score: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Assuming X and y are your features and target variable\n",
    "# Define the model with regularization parameters\n",
    "regressor = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=8,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "# Set up k-fold cross-validation (8 folds)\n",
    "kf = KFold(n_splits=8, shuffle=True, random_state=42)\n",
    "# Perform cross-validation and calculate MSE for each fold\n",
    "scores = cross_val_score(\n",
    "    regressor, X, y, cv=kf, scoring=make_scorer(mean_squared_error)\n",
    ")\n",
    "# Calculate the mean and standard deviation of the MSE scores\n",
    "mean_mse = np.mean(scores)\n",
    "std_mse = np.std(scores)\n",
    "print(f\"Mean MSE from cross-validation: {mean_mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Mean Squared Error: 7.757442405928452\n",
      "Gradient Boosting Regressor R^2 Score: 0.8958915564195972\n"
     ]
    }
   ],
   "source": [
    "#define the gradient boosting model with different parameters\n",
    "gbm_model = GradientBoostingRegressor(n_estimators=300, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_gbm = gbm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Gradient Boosting Regressor\n",
    "print(\"Gradient Boosting Regressor Mean Squared Error:\", mean_squared_error(y_test, y_pred_gbm))\n",
    "print(\"Gradient Boosting Regressor R^2 Score:\", r2_score(y_test, y_pred_gbm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge MSE: 21.5485004029582\n",
      "Ridge R^2 Score: 0.7108092176450825\n",
      "Lasso MSE: 22.79791327777329\n",
      "Lasso R^2 Score: 0.6940415224460941\n",
      "Elastic Net MSE: 22.480044769402568\n",
      "Elastic Net R^2 Score: 0.6983074639688323\n"
     ]
    }
   ],
   "source": [
    "# L2 Regularization: Ridge Regression\n",
    "ridge = Ridge(alpha=1.0)  # alpha controls the regularization strength; higher means more regularization\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_predictions = ridge.predict(X_test)\n",
    "print(\"Ridge MSE:\", mean_squared_error(y_test, ridge_predictions))\n",
    "print(\"Ridge R^2 Score:\", r2_score(y_test, ridge_predictions))\n",
    "\n",
    "# L1 Regularization: Lasso Regression\n",
    "lasso = Lasso(alpha=0.1)  # alpha is the regularization parameter\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_predictions = lasso.predict(X_test)\n",
    "print(\"Lasso MSE:\", mean_squared_error(y_test, lasso_predictions))\n",
    "print(\"Lasso R^2 Score:\", r2_score(y_test, lasso_predictions))\n",
    "\n",
    "# L1 + L2 Regularization: Elastic Net\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)  # l1_ratio balances between L1 and L2 (0 = pure L2, 1 = pure L1)\n",
    "elastic_net.fit(X_train, y_train)\n",
    "elastic_net_predictions = elastic_net.predict(X_test)\n",
    "print(\"Elastic Net MSE:\", mean_squared_error(y_test, elastic_net_predictions))\n",
    "print(\"Elastic Net R^2 Score:\", r2_score(y_test, elastic_net_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "Linear Regression - 0.7112260057484925,\n",
    "Random Forest Regressor - 0.8710341288379007,\n",
    "Random Forest Regressor with regularization - 0.8710341288379007,\n",
    "Gradient Boosting Regressor - 0.8958915564195972,\n",
    "Ridge Regression - 0.7108092176450825,\n",
    "Lasso Regression - 0.6940415224460941,\n",
    "Elastic Regression - 0.6983074639688323,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
